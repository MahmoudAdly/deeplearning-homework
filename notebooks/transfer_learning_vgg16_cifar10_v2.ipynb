{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_vgg16_cifar10_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AgL4vv23v24J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to install kiras\n",
        "# !pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTqCOrLLwbEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "919245b8-2e65-4442-b720-c531fba5591f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import Input, Flatten, Dense, Lambda, Dropout, Activation\n",
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.backend import tf as ktf\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EuEVZP-ww2ey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = ktf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CK8vjZoZxQHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load data and prepare it"
      ]
    },
    {
      "metadata": {
        "id": "YZJwUjDXxW7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_blk56GxZXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "6755f25e-0063-4992-8220-e718d02f7c80"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_train[0][0])\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "[[ 59  62  63]\n",
            " [ 43  46  45]\n",
            " [ 50  48  43]\n",
            " [ 68  54  42]\n",
            " [ 98  73  52]\n",
            " [119  91  63]\n",
            " [139 107  75]\n",
            " [145 110  80]\n",
            " [149 117  89]\n",
            " [149 120  93]\n",
            " [131 103  77]\n",
            " [125  99  76]\n",
            " [142 115  91]\n",
            " [144 112  86]\n",
            " [137 105  79]\n",
            " [129  97  71]\n",
            " [137 106  79]\n",
            " [134 106  76]\n",
            " [124  97  64]\n",
            " [139 113  78]\n",
            " [139 112  75]\n",
            " [133 105  69]\n",
            " [136 105  74]\n",
            " [139 108  77]\n",
            " [152 120  89]\n",
            " [163 131 100]\n",
            " [168 136 108]\n",
            " [159 129 102]\n",
            " [158 130 104]\n",
            " [158 132 108]\n",
            " [152 125 102]\n",
            " [148 124 103]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9421de9828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlJgsCQiUmCwJCJSYLAkIlL4/wKvOysvkgncAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94d7a59128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DxrLDehST1u9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f5OoOt7TUbvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "7ff7e4d9-a949-41d3-a456-2f085a90c85f"
      },
      "cell_type": "code",
      "source": [
        "print(X_train[0][0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.23137255 0.24313726 0.24705882]\n",
            " [0.16862746 0.18039216 0.1764706 ]\n",
            " [0.19607843 0.1882353  0.16862746]\n",
            " [0.26666668 0.21176471 0.16470589]\n",
            " [0.38431373 0.28627452 0.20392157]\n",
            " [0.46666667 0.35686275 0.24705882]\n",
            " [0.54509807 0.41960785 0.29411766]\n",
            " [0.5686275  0.43137255 0.3137255 ]\n",
            " [0.58431375 0.45882353 0.34901962]\n",
            " [0.58431375 0.47058824 0.3647059 ]\n",
            " [0.5137255  0.40392157 0.3019608 ]\n",
            " [0.49019608 0.3882353  0.29803923]\n",
            " [0.5568628  0.4509804  0.35686275]\n",
            " [0.5647059  0.4392157  0.3372549 ]\n",
            " [0.5372549  0.4117647  0.30980393]\n",
            " [0.5058824  0.38039216 0.2784314 ]\n",
            " [0.5372549  0.41568628 0.30980393]\n",
            " [0.5254902  0.41568628 0.29803923]\n",
            " [0.4862745  0.38039216 0.2509804 ]\n",
            " [0.54509807 0.44313726 0.30588236]\n",
            " [0.54509807 0.4392157  0.29411766]\n",
            " [0.52156866 0.4117647  0.27058825]\n",
            " [0.53333336 0.4117647  0.2901961 ]\n",
            " [0.54509807 0.42352942 0.3019608 ]\n",
            " [0.59607846 0.47058824 0.34901962]\n",
            " [0.6392157  0.5137255  0.39215687]\n",
            " [0.65882355 0.53333336 0.42352942]\n",
            " [0.62352943 0.5058824  0.4       ]\n",
            " [0.61960787 0.50980395 0.40784314]\n",
            " [0.61960787 0.5176471  0.42352942]\n",
            " [0.59607846 0.49019608 0.4       ]\n",
            " [0.5803922  0.4862745  0.40392157]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w5mKhizhxdZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5fbc23f6-6307-49d3-cdb8-21f2d138de22"
      },
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1)\n",
            "[6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lbYlpKcJxjum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert class values to one-hot categorical values\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-M1vQtaAUfc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e251cc53-2f48-4a3c-a698-843bfb172e62"
      },
      "cell_type": "code",
      "source": [
        "print(Y_train[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Yp1XWcCxr4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### My images' size is 32x32. But to be able to use the pre-trained model weights, we have to enlarge them.\n",
        "\n",
        "\n",
        "### Let's do it as a layer in the model."
      ]
    },
    {
      "metadata": {
        "id": "4nM3ay_rxu81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load VGG16 model and customize it"
      ]
    },
    {
      "metadata": {
        "id": "SZ6OAgG4mhCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = 64\n",
        "dropout = 0.5\n",
        "batch_size = 64\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zLY0bEixxki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_model = VGG16(include_top=False, input_shape=(image_size, image_size, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXrcBYc1x3D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "b9f97643-5921-4391-9de3-bc78838109be"
      },
      "cell_type": "code",
      "source": [
        "print(vgg16_model.summary())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-pUjIPZcI4LO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(None, None, 3))\n",
        "\n",
        "x = Lambda(lambda image: ktf.image.resize_images(image, (image_size, image_size)))(inp)\n",
        "\n",
        "# No need to retrain the network.\n",
        "for layer in vgg16_model.layers:\n",
        "  layer.trainable = False\n",
        "  x = layer(x)\n",
        "\n",
        "# Add the fully-connected layers at the end\n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(dropout)(x)\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(dropout)(x)\n",
        "x = Dense(10, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = Model(inputs=inp, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7py-e07I_NC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1233
        },
        "outputId": "9e2d8d3f-0e47-4e9b-b66c-ce26bf85c526"
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 39,962,442\n",
            "Trainable params: 25,231,370\n",
            "Non-trainable params: 14,731,072\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lrnTKjf2x7IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "17971f3d-d7fd-4b90-db45-6919f679b8dc"
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model.fit(x=X_train, y=Y_train, validation_split=0.1, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print (\"Training done in {} seconds.\".format(elapsed_time))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(\"Accuracy: {0}\".format(score[1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 76s 2ms/step - loss: 1.6272 - acc: 0.5536 - val_loss: 1.2927 - val_acc: 0.6348\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 1.1779 - acc: 0.6356 - val_loss: 1.0227 - val_acc: 0.6756\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 1.0509 - acc: 0.6636 - val_loss: 0.9643 - val_acc: 0.6968\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.9715 - acc: 0.6838 - val_loss: 0.9692 - val_acc: 0.6938\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.9115 - acc: 0.6961 - val_loss: 0.9323 - val_acc: 0.6978\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.8640 - acc: 0.7102 - val_loss: 0.9296 - val_acc: 0.7098\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.8197 - acc: 0.7241 - val_loss: 0.9075 - val_acc: 0.7130\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 0.7863 - acc: 0.7316 - val_loss: 0.8841 - val_acc: 0.7130\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 0.7512 - acc: 0.7454 - val_loss: 0.8618 - val_acc: 0.7214\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 0.7196 - acc: 0.7540 - val_loss: 0.8548 - val_acc: 0.7352\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 0.6926 - acc: 0.7607 - val_loss: 0.8825 - val_acc: 0.7254\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.6674 - acc: 0.7706 - val_loss: 0.8883 - val_acc: 0.7112\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 0.6405 - acc: 0.7793 - val_loss: 0.8292 - val_acc: 0.7326\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.6118 - acc: 0.7859 - val_loss: 0.8411 - val_acc: 0.7328\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.5904 - acc: 0.7937 - val_loss: 0.8605 - val_acc: 0.7474\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.5677 - acc: 0.8015 - val_loss: 0.8309 - val_acc: 0.7378\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.5558 - acc: 0.8067 - val_loss: 0.8222 - val_acc: 0.7420\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.5288 - acc: 0.8133 - val_loss: 0.8368 - val_acc: 0.7432\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.5095 - acc: 0.8205 - val_loss: 0.8399 - val_acc: 0.7410\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 0.4949 - acc: 0.8262 - val_loss: 0.8469 - val_acc: 0.7392\n",
            "Training done in 1466.555470943451 seconds.\n",
            "10000/10000 [==============================] - 13s 1ms/step\n",
            "Accuracy: 0.7333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IU1EJtZNJ7Ay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ]
    },
    {
      "metadata": {
        "id": "7EZVqtTRKBnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Even though I had the computation power this time by using Google Colaboratory and could expriment by trying and shuffling so many hyperparameters and optimizers and extra layers, I still struggled to reach something above 74% accuracy. And each trial of fine-tuning was still clearly reaching a point of overfitting. Which was strange to have a lower accuracy than my own model's accuracy of 82.68% found [here](./cnn_cifar10_v2.ipynb).\n",
        "\n",
        "But my assumption so far, and from online posts/discussions, is that such model indeed needs more finetuning. Which does not make sense in my case to put more effort in it because  I could work on my own solution anyways to make it better if I want to."
      ]
    },
    {
      "metadata": {
        "id": "YHp3JrqZLnKf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}